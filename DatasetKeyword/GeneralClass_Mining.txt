{'BIG Environment Genetic Selection applications':['fully observable','partially observable','limited intelligence','knowledge','experience','decisions sequentially','volume','big_data','variety','velocity','unstructured data','semi-structured data','value','veracity','machine_learning','structured data','performance_measure','single_agent','environment','actuators','sensors','peas','fully_observable','partially_observable','static_environment','dynamic_environment','single_agent','multi_agent','known_environment','unknown_environment','episodic','deterministic','static_environment','sequential','inaccessible','accessible','fitness proportionate','probability','roulette_wheel','tournament selection','rank selection','gene','chromosome','genotype','phenotype','generation','bit string'],'Intelligence agent':['ai','rational_agent','artificial agent','robotics','interface agent','intelligent agent','performance_measure','single_agent','environment','actuators','sensors','multi_agent','peas','model_based_agent','goal_based','reflex_agent','utility_based','learning_agent','current percepts','fully observable','partially observable','limited intelligence','learning agent','reinforcement_learning','performance','critic','learning element','experience','decisions sequentially','chess game','negative reinforcement','positive reinforcement','thinking_humanly','thinking_rationally','acting_humanly','acting_rationally','machine_learning'],'heuristic Evolutionary search':['global search','local search','heuristic','uninformed_search','informed_search','evolutionary_algorithm','greedy','beam_search','depth_first_search','hill_climbing','simulated_annealing','particle_swarm_optimization','depth_first_branch_and_bound','genetic_algorithm','evolutionary_algorithm','differential_evolution','fitness proportionate','probability','roulette_wheel','tournament selection','rank selection','gene','chromosome','genotype','phenotype','generation','bit string'],'learning clustering':['support_vector_machine','neural_network','classification','regression','classifier','linear regression','machine_learning','reinforcement_learning','labeled data','hierarchical_clustering','partitional_clustering','affinity_propagation','dbscan','spectral_clustering','mean_shift','cluster','unknown pattern','unpredictable','connectivity model','k-means','nested cluster','contiguity-based','center-based','Well-Separated','centroid-based','density-based','current percepts','fully observable','partially observable','limited intelligence','knowledge','learning agent','limited intelligence','negative reinforcement','positive reinforcement','backpropagation'],'others':['minkowski_distance','euclidean_distance','jaro_winkler_distance','levenshtein_distance','coefficient','cosine_similarity','simple_matching_coefficient','jaccard','hamming_distance','imitation_game','turing_test','alan turing','chinese_room','kenneth','joseph','eliza','searle','cluster','unknown pattern','unpredictable','hierarchical clustering','robotics','industrial automation','machine_learning','data processing','training system','fully observable','partially observable','limited intelligence','knowledge','experience','decisions sequentially','chess game','negative reinforcement','positive reinforcement','backpropagation']}
