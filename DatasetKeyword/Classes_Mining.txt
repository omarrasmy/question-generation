{'big data':['volume','big_data','variety','velocity','unstructured data','semi-structured data','value','veracity','machine_learning','structured data'],'experiment':['imitation_game','turing_test','alan turing','chinese_room','kenneth','joseph','eliza','searle'],'rational agent':['performance_measure','single_agent','environment','actuators','sensors','multi_agent','artificial agent','intelligent agent','robotics','interface agent','peas'],'environment types':['fully_observable','partially_observable','static_environment','dynamic_environment','single_agent','multi_agent','known_environment','unknown_environment','episodic','deterministic','static_environment','sequential','inaccessible','accessible'],'agent types':['rational_agent','artificial agent','interface agent','intelligent agent','model_based_agent','goal_based','reflex_agent','utility_based','learning_agent'],'search type':['global search','local search','heuristic','uninformed_search','informed_search','evolutionary_algorithm'],'heuristic':['global search','local search','uninformed_search','informed_search','evolutionary_algorithm','greedy'],'local informed search':['greedy','beam_search','depth_first_search','heuristic','hill_climbing','simulated_annealing','particle_swarm_optimization'],'global informed search':['greedy','heuristic','simulated_annealing','hill_climbing','particle_swarm_optimization'],'evolutionary algorithm':['simulated_annealing','particle_swarm_optimization','genetic_algorithm','evolutionary_algorithm','differential_evolution','global search','local search','breadth_first_search'],'selection type':['fitness proportionate','probability','roulette_wheel','tournament selection','rank selection'],'genetic population representation':['gene','chromosome','genotype','phenotype','generation','bit string'],'distance measure':['minkowski_distance','euclidean_distance','jaro_winkler_distance','levenshtein_distance','coefficient','cosine_similarity','simple_matching_coefficient','jaccard','hamming_distance'],'supervised learning':['support_vector_machine','neural_network','classification','regression','classifier','linear regression','machine_learning','reinforcement_learning','labeled data','hierarchical_clustering','partitional_clustering'],'unsupervised learning':['affinity_propagation','dbscan','spectral_clustering','mean_shift','support_vector_machine','neural_network','reinforcement_learning','cluster','unknown pattern','unpredictable','hierarchical_clustering','partitional_clustering','connectivity model','k-means','nested cluster','contiguity-based','center-based','well-separated','centroid-based','density-based'],'clustering':['affinity_propagation','dbscan','spectral_clustering','mean_shift','cluster','unknown pattern','unpredictable','center-based','well-separated','centroid-based','density-based','hierarchical_clustering','partitional_clustering','connectivity model','k-means'],'k-means':['affinity_propagation','dbscan','spectral_clustering','mean_shift','cluster','center-based','well-separated','centroid-based','density-based','hierarchical_clustering','partitional_clustering','centroid','unknown pattern','unpredictable','connectivity model'],'hierachical clustering':['cluster','unknown pattern','unpredictable','hierarchical clustering','connectivity model','k-means'],'simple reflex agent':['current percepts','fully observable','partially observable','limited intelligence','learning agent','reinforcement_learning'],'model-based reflex agent':['current percepts','fully observable','partially observable','limited intelligence','knowledge','learning agent','reinforcement_learning'],'learning agents':['ai','performance','critic','learning element','fully observable','partially observable','limited intelligence','knowledge','learning agent','reinforcement_learning'],'reinforcement learning':['fully observable','partially observable','limited intelligence','knowledge','learning agent','reinforcement_learning','experience','decisions sequentially','chess game','negative reinforcement','positive reinforcement'],'positive learning':['fully observable','partially observable','limited intelligence','knowledge','learning agent','reinforcement_learning','experience','decisions sequentially','chess game','negative reinforcement','positive reinforcement','maximize performance'],'applications of reinforcement learning':['robotics','industrial automation','machine_learning','data processing','training system'],'artificial intelligence':['thinking_humanly','thinking_rationally','acting_humanly','acting_rationally','ai','rational_agent','intelligent agent']}
